Machine Learning for Signals, Information, and Data
Covers supervised learning techniques: 
- Regression-> least squares, regularization (ridge, lasso), underdetermined problems, kernel regression with Gaussian processes
- Classification-> Naive Bayes, full Bayes, perceptron, SVM dual formulation, gradient descent, kernel methods, decision trees, boosting, bagging
Unsupervised learning:
- Clustering-> K-means, EM for mixture models, missing data
- Low-rank models-> PCA, kernel PCA, collaborative filtering, topic models, association learning, matrix factorization, NMF, hyperspectral unmixing

These assignments are:
- Derive and code ridge regression algorithm to predict miles per gallon a car will get using six features.
- Derive and code a Naive Bayes classifier and a k-NN algorithm to classify between spam and not-spam emails, code a Gaussian process model for regression to predict miles per gallon again.
- "Netflix problem": derive and code a matrix factorization method with gradient descent to predict users' affinity for movies which they have not yet rated.
- Derive and code a non-negative matrix factorization method to text mine New York Times documents.
